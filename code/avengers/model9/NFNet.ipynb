{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "package_paths = [\n",
    "    '/workspace/input/pytorch-image-models/timm', #'../input/efficientnet-pytorch-07/efficientnet_pytorch-0.7.0'\n",
    "    '/workspace/pytorch-image-models/pytorch-image-models-master'\n",
    "]\n",
    "import sys; \n",
    "\n",
    "for pth in package_paths:\n",
    "    sys.path.append(pth)\n",
    "    \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5' # specify GPUs locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 2.173722,
     "end_time": "2020-11-23T13:32:49.521795",
     "exception": false,
     "start_time": "2020-11-23T13:32:47.348073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "import cv2\n",
    "from skimage import io\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from adamp import AdamP\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#import timm\n",
    "\n",
    "import sklearn\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import cv2\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "from scipy.ndimage.interpolation import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_image_models.timm as timm\n",
    "\n",
    "from nfnets.agc import AGC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.026635,
     "end_time": "2020-11-23T13:32:49.570638",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.544003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 719,\n",
    "    'model_arch': 'nf_resnet50',\n",
    "    'model_path': 'nf_resnet50_agc_clipping_03',\n",
    "    'input_size':512,\n",
    "    'img_size': 512,\n",
    "    'epochs': 20,\n",
    "    'train_bs': 32,\n",
    "    'valid_bs': 32,\n",
    "    'T_0': 20,\n",
    "    'lr': 1e-4,\n",
    "    'min_lr': 1e-6,\n",
    "    'weight_decay':1e-6,\n",
    "    'freeze_bn_epochs': 0,\n",
    "    'num_workers': 0,\n",
    "    'accum_iter': 1, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "    'verbose_step': 1,\n",
    "    'device': 'cuda:0',\n",
    "    'target_size' : 5, \n",
    "    'smoothing' : 0.2,\n",
    "    'clipping' : 0.3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(CFG['model_path']):\n",
    "    os.makedirs(CFG['model_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "papermill": {
     "duration": 0.057123,
     "end_time": "2020-11-23T13:32:49.643710",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.586587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  1000015157.jpg      0\n",
       "1  1000201771.jpg      3\n",
       "2   100042118.jpg      1\n",
       "3  1000723321.jpg      1\n",
       "4  1000812911.jpg      3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('/workspace/input/cassava-leaf-disease-classification/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.028528,
     "end_time": "2020-11-23T13:32:49.688153",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.659625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    13158\n",
       "4     2577\n",
       "2     2386\n",
       "1     2189\n",
       "0     1087\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016085,
     "end_time": "2020-11-23T13:32:49.720073",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.703988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> We could do stratified validation split in each fold to make each fold's train and validation set looks like the whole train set in target distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.032053,
     "end_time": "2020-11-23T13:32:49.768481",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.736428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2216849948.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  2216849948.jpg      4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('/workspace/input/cassava-leaf-disease-classification/sample_submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015931,
     "end_time": "2020-11-23T13:32:49.801027",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.785096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 0.315262,
     "end_time": "2020-11-23T13:32:50.132792",
     "exception": false,
     "start_time": "2020-11-23T13:32:49.817530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    #print(im_rgb)\n",
    "    return im_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021311,
     "end_time": "2020-11-23T13:32:50.174973",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.153662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 0.064816,
     "end_time": "2020-11-23T13:32:50.261340",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.196524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[0]\n",
    "    H = size[1]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, df, data_root, \n",
    "                 transforms=None, \n",
    "                 output_label=True, \n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms = transforms\n",
    "        self.data_root = data_root\n",
    "        \n",
    "        self.output_label = output_label\n",
    "        self.labels = self.df['label'].values\n",
    "\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # get labels\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "          \n",
    "        img  = get_img(\"{}/{}\".format(self.data_root, self.df.loc[index]['image_id']))\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "        \n",
    "        if self.output_label == True:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02183,
     "end_time": "2020-11-23T13:32:50.304795",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.282965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Train\\Validation Image Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations.core.transforms_interface import DualTransform\n",
    "from albumentations.augmentations import functional as F\n",
    "class GridMask(DualTransform):\n",
    "    \"\"\"GridMask augmentation for image classification and object detection.\n",
    "    \n",
    "    Author: Qishen Ha\n",
    "    Email: haqishen@gmail.com\n",
    "    2020/01/29\n",
    "\n",
    "    Args:\n",
    "        num_grid (int): number of grid in a row or column.\n",
    "        fill_value (int, float, lisf of int, list of float): value for dropped pixels.\n",
    "        rotate ((int, int) or int): range from which a random angle is picked. If rotate is a single int\n",
    "            an angle is picked from (-rotate, rotate). Default: (-90, 90)\n",
    "        mode (int):\n",
    "            0 - cropout a quarter of the square of each grid (left top)\n",
    "            1 - reserve a quarter of the square of each grid (left top)\n",
    "            2 - cropout 2 quarter of the square of each grid (left top & right bottom)\n",
    "\n",
    "    Targets:\n",
    "        image, mask\n",
    "\n",
    "    Image types:\n",
    "        uint8, float32\n",
    "\n",
    "    Reference:\n",
    "    |  https://arxiv.org/abs/2001.04086\n",
    "    |  https://github.com/akuxcw/GridMask\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_grid=3, fill_value=0, rotate=0, mode=0, always_apply=False, p=0.5):\n",
    "        super(GridMask, self).__init__(always_apply, p)\n",
    "        if isinstance(num_grid, int):\n",
    "            num_grid = (num_grid, num_grid)\n",
    "        if isinstance(rotate, int):\n",
    "            rotate = (-rotate, rotate)\n",
    "        self.num_grid = num_grid\n",
    "        self.fill_value = fill_value\n",
    "        self.rotate = rotate\n",
    "        self.mode = mode\n",
    "        self.masks = None\n",
    "        self.rand_h_max = []\n",
    "        self.rand_w_max = []\n",
    "\n",
    "    def init_masks(self, height, width):\n",
    "        if self.masks is None:\n",
    "            self.masks = []\n",
    "            n_masks = self.num_grid[1] - self.num_grid[0] + 1\n",
    "            for n, n_g in enumerate(range(self.num_grid[0], self.num_grid[1] + 1, 1)):\n",
    "                grid_h = height / n_g\n",
    "                grid_w = width / n_g\n",
    "                this_mask = np.ones((int((n_g + 1) * grid_h), int((n_g + 1) * grid_w))).astype(np.uint8)\n",
    "                for i in range(n_g + 1):\n",
    "                    for j in range(n_g + 1):\n",
    "                        this_mask[\n",
    "                             int(i * grid_h) : int(i * grid_h + grid_h / 2),\n",
    "                             int(j * grid_w) : int(j * grid_w + grid_w / 2)\n",
    "                        ] = self.fill_value\n",
    "                        if self.mode == 2:\n",
    "                            this_mask[\n",
    "                                 int(i * grid_h + grid_h / 2) : int(i * grid_h + grid_h),\n",
    "                                 int(j * grid_w + grid_w / 2) : int(j * grid_w + grid_w)\n",
    "                            ] = self.fill_value\n",
    "                \n",
    "                if self.mode == 1:\n",
    "                    this_mask = 1 - this_mask\n",
    "\n",
    "                self.masks.append(this_mask)\n",
    "                self.rand_h_max.append(grid_h)\n",
    "                self.rand_w_max.append(grid_w)\n",
    "\n",
    "    def apply(self, image, mask, rand_h, rand_w, angle, **params):\n",
    "        h, w = image.shape[:2]\n",
    "        mask = F.rotate(mask, angle) if self.rotate[1] > 0 else mask\n",
    "        mask = mask[:,:,np.newaxis] if image.ndim == 3 else mask\n",
    "        image *= mask[rand_h:rand_h+h, rand_w:rand_w+w].astype(image.dtype)\n",
    "        return image\n",
    "\n",
    "    def get_params_dependent_on_targets(self, params):\n",
    "        img = params['image']\n",
    "        height, width = img.shape[:2]\n",
    "        self.init_masks(height, width)\n",
    "\n",
    "        mid = np.random.randint(len(self.masks))\n",
    "        mask = self.masks[mid]\n",
    "        rand_h = np.random.randint(self.rand_h_max[mid])\n",
    "        rand_w = np.random.randint(self.rand_w_max[mid])\n",
    "        angle = np.random.randint(self.rotate[0], self.rotate[1]) if self.rotate[1] > 0 else 0\n",
    "\n",
    "        return {'mask': mask, 'rand_h': rand_h, 'rand_w': rand_w, 'angle': angle}\n",
    "\n",
    "    @property\n",
    "    def targets_as_params(self):\n",
    "        return ['image']\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return ('num_grid', 'fill_value', 'rotate', 'mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 0.590042,
     "end_time": "2020-11-23T13:32:50.916225",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.326183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize, Rotate\n",
    ")\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_train_transforms():\n",
    "    return Compose([\n",
    "            OneOf([\n",
    "                Resize(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "                CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "                RandomResizedCrop(CFG['img_size'], CFG['img_size'], p=1.)\n",
    "            ], p=1.), \n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            CoarseDropout(p=0.5),\n",
    "            GridMask(num_grid=3, p=0.5),\n",
    "            Cutout(p=0.5),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "\n",
    "\n",
    "        \n",
    "def get_valid_transforms():\n",
    "    return Compose([\n",
    "            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "            Resize(CFG['img_size'], CFG['img_size']),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024452,
     "end_time": "2020-11-23T13:32:50.962106",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.937654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "papermill": {
     "duration": 0.033239,
     "end_time": "2020-11-23T13:32:51.017593",
     "exception": false,
     "start_time": "2020-11-23T13:32:50.984354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CassvaImgClassifier_NF(nn.Module):\n",
    "    def __init__(self, model_arch, n_class,img_size, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        #n_features = self.model.head.num_pooled_features\n",
    "        self.model.head.fc = nn.Linear(2048, n_class)\n",
    "#         self.model.classifier = nn.Sequential(\n",
    "#             nn.Linear(n_features, n_features//2),\n",
    "#             nn.LeakyReLU(inplace=True),\n",
    "#             nn.Linear(n_features//2, n_class)\n",
    "#         )\n",
    "        \n",
    "        for module in self.model.modules():\n",
    "            #print(module)\n",
    "            if isinstance(module, nn.BatchNorm2d):\n",
    "                if hasattr(module, 'weight'):\n",
    "                    module.weight.requires_grad_(False)\n",
    "                if hasattr(module, 'bias'):\n",
    "                    module.bias.requires_grad_(False)\n",
    "                #module.eval()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CassvaImgClassifier_NF(\n",
      "  (model): NormFreeNet(\n",
      "    (stem): Sequential(\n",
      "      (conv): ScaledStdConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (stages): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): NormFreeBlock(\n",
      "          (downsample): DownsampleAvg(\n",
      "            (pool): Identity()\n",
      "            (conv): ScaledStdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (act1): ReLU()\n",
      "          (conv1): ScaledStdConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv2): ScaledStdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (act3): ReLU()\n",
      "          (conv3): ScaledStdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): NormFreeBlock(\n",
      "          (act1): ReLU()\n",
      "          (conv1): ScaledStdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv2): ScaledStdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (act3): ReLU()\n",
      "          (conv3): ScaledStdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): NormFreeBlock(\n",
      "          (act1): ReLU()\n",
      "          (conv1): ScaledStdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv2): ScaledStdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (act3): ReLU()\n",
      "          (conv3): ScaledStdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): NormFreeBlock(\n",
      "          (downsample): DownsampleAvg(\n",
      "            (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "            (conv): ScaledStdConv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (act1): ReLU()\n",
      "          (conv1): ScaledStdConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv2): ScaledStdConv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (act3): ReLU()\n",
      "          (conv3): ScaledStdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): NormFreeBlock(\n",
      "          (act1): ReLU()\n",
      "          (conv1): ScaledStdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv2): ScaledStdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (act3): ReLU()\n",
      "          (conv3): ScaledStdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): NormFreeBlock(\n",
      "          (act1): ReLU()\n",
      "          (conv1): ScaledStdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv2): ScaledStdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (act3): ReLU()\n",
      "          (conv3): ScaledStdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (3): NormFreeBlock(\n",
      "          (act1): ReLU()\n",
      "          (conv1): ScaledStdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv2): ScaledStdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (act3): ReLU()\n",
      "          (conv3): ScaledStdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): NormFreeBlock(\n",
      "          (downsample): DownsampleAvg(\n",
      "            (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "            (conv): ScaledStdConv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (act1): ReLU()\n",
      "          (conv1): ScaledStdConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv2): ScaledStdConv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (act3): ReLU()\n",
      "          (conv3): ScaledStdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): NormFreeBlock(\n",
      "          (act1): ReLU()\n",
      "          (conv1): ScaledStdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv2): ScaledStdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (act3): ReLU()\n",
      "          (conv3): ScaledStdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): NormFreeBlock(\n",
      "          (act1): ReLU()\n",
      "          (conv1): ScaledStdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv2): ScaledStdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (act3): ReLU()\n",
      "          (conv3): ScaledStdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (3): NormFreeBlock(\n",
      "          (act1): ReLU()\n",
      "          (conv1): ScaledStdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv2): ScaledStdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (act3): ReLU()\n",
      "          (conv3): ScaledStdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (4): NormFreeBlock(\n",
      "          (act1): ReLU()\n",
      "          (conv1): ScaledStdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv2): ScaledStdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (act3): ReLU()\n",
      "          (conv3): ScaledStdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (5): NormFreeBlock(\n",
      "          (act1): ReLU()\n",
      "          (conv1): ScaledStdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv2): ScaledStdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (act3): ReLU()\n",
      "          (conv3): ScaledStdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): NormFreeBlock(\n",
      "          (downsample): DownsampleAvg(\n",
      "            (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "            (conv): ScaledStdConv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (act1): ReLU()\n",
      "          (conv1): ScaledStdConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv2): ScaledStdConv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (act3): ReLU()\n",
      "          (conv3): ScaledStdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): NormFreeBlock(\n",
      "          (act1): ReLU()\n",
      "          (conv1): ScaledStdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv2): ScaledStdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (act3): ReLU()\n",
      "          (conv3): ScaledStdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): NormFreeBlock(\n",
      "          (act1): ReLU()\n",
      "          (conv1): ScaledStdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (conv2): ScaledStdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (act3): ReLU()\n",
      "          (conv3): ScaledStdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_conv): Identity()\n",
      "    (final_act): ReLU()\n",
      "    (head): ClassifierHead(\n",
      "      (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
      "      (fc): Linear(in_features=2048, out_features=5, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "tmp_model = CassvaImgClassifier_NF(CFG['model_arch'], 5, 512, pretrained=True)\n",
    "print(tmp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassvaImgClassifier_ViT(nn.Module):\n",
    "    def __init__(self, model_arch, n_class, img_size, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, img_size=img_size, pretrained=pretrained)\n",
    "        #if pretrained:\n",
    "        #    self.model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, n_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021054,
     "end_time": "2020-11-23T13:32:51.059722",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.038668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "papermill": {
     "duration": 0.061685,
     "end_time": "2020-11-23T13:32:51.144150",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.082465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_dataloader(df, trn_idx, val_idx, data_root='./cassava-leaf-disease-classification/train_images/'):\n",
    "    \n",
    "    # from catalyst.data.sampler import BalanceClassSampler\n",
    "    \n",
    "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n",
    "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n",
    "        \n",
    "    train_ds = CassavaDataset(train_, data_root, transforms=get_train_transforms(), output_label=True)\n",
    "    valid_ds = CassavaDataset(valid_, data_root, transforms=get_valid_transforms(), output_label=True)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        pin_memory=False,\n",
    "        drop_last=False,\n",
    "        shuffle=True,        \n",
    "        num_workers=CFG['num_workers'],\n",
    "        #sampler=BalanceClassSampler(labels=train_['label'].values, mode=\"downsampling\")\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=CFG['valid_bs'],\n",
    "        num_workers=CFG['num_workers'],\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None, schd_batch_update=False):\n",
    "    #model.train()\n",
    "\n",
    "    t = time.time()\n",
    "    running_loss = None\n",
    "\n",
    "    # pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in enumerate(train_loader):\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "\n",
    "        with autocast():\n",
    "            image_preds = model(imgs)   #output = model(input)\n",
    "            loss = loss_fn(image_preds, image_labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if running_loss is None:\n",
    "                running_loss = loss.item()\n",
    "            else:\n",
    "                running_loss = running_loss * .99 + loss.item() * .01\n",
    "\n",
    "            if ((step + 1) %  CFG['accum_iter'] == 0) or ((step + 1) == len(train_loader)):\n",
    "\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad() \n",
    "                \n",
    "                if scheduler is not None and schd_batch_update:\n",
    "                    scheduler.step()\n",
    "\n",
    "            #if step % 150 == 0:\n",
    "            #    print(f\"step : {step}/{len(train_loader)}, loss : {running_loss}\")\n",
    "            # if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n",
    "            #     description = f'epoch {epoch} loss: {running_loss:.4f}'\n",
    "            #     print(description)\n",
    "                # pbar.set_description(description)\n",
    "                \n",
    "    if scheduler is not None and not schd_batch_update:\n",
    "        scheduler.step()\n",
    "        \n",
    "def valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n",
    "    model.eval()\n",
    "\n",
    "    t = time.time()\n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "    \n",
    "    # pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    for step, (imgs, image_labels) in enumerate(val_loader):\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "        \n",
    "        image_preds = model(imgs)   #output = model(input)\n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "        \n",
    "        loss = loss_fn(image_preds, image_labels)\n",
    "        \n",
    "        loss_sum += loss.item()*image_labels.shape[0]\n",
    "        sample_num += image_labels.shape[0]  \n",
    "\n",
    "        # if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(val_loader)):\n",
    "        #     description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n",
    "        #     pbar.set_description(description)\n",
    "    \n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    print('epoch = {}'.format(epoch+1), f'loss = {loss}', 'validation multi-class accuracy = {:.4f}'.format((image_preds_all==image_targets_all).mean()))\n",
    "    \n",
    "    if scheduler is not None:\n",
    "        if schd_loss_update:\n",
    "            scheduler.step(loss_sum/sample_num)\n",
    "        else:\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_batchnorm_stats(net):\n",
    "    net.train()\n",
    "    try:\n",
    "        for m in net.modules():\n",
    "            if isinstance(m,nn.BatchNorm2d) or isinstance(m,nn.LayerNorm):\n",
    "                m.eval()\n",
    "    except ValuError:\n",
    "        print('error with batchnorm2d or layernorm')\n",
    "        return\n",
    "    \n",
    "def unfreeze_batchnorm_stats(net):\n",
    "    net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "papermill": {
     "duration": 0.034873,
     "end_time": "2020-11-23T13:32:51.200704",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.165831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    \"\"\"\n",
    "    NLL loss with label smoothing.\n",
    "    \"\"\"\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        \"\"\"\n",
    "        Constructor for the LabelSmoothing module.\n",
    "        :param smoothing: label smoothing factor\n",
    "        \"\"\"\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        assert smoothing < 1.0\n",
    "        self.smoothing = smoothing\n",
    "        self.confidence = 1. - smoothing\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n",
    "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Label Smoothing\n",
    "# ====================================================\n",
    "class LabelSmoothingLoss(nn.Module): \n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1): \n",
    "        super(LabelSmoothingLoss, self).__init__() \n",
    "        self.confidence = 1.0 - smoothing \n",
    "        self.smoothing = smoothing \n",
    "        self.cls = classes \n",
    "        self.dim = dim \n",
    "        \n",
    "    def forward(self, pred, target): \n",
    "        pred = pred.log_softmax(dim=self.dim) \n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred) \n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1)) \n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence) \n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020806,
     "end_time": "2020-11-23T13:32:51.243006",
     "exception": false,
     "start_time": "2020-11-23T13:32:51.222200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchcontrib.optim import SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 0 started\n",
      "17117 4280\n",
      "epoch = 1 loss = 0.5826820135116577 validation multi-class accuracy = 0.8687\n",
      "epoch = 2 loss = 0.5017291307449341 validation multi-class accuracy = 0.8773\n",
      "epoch = 3 loss = 0.5165225863456726 validation multi-class accuracy = 0.8636\n",
      "epoch = 4 loss = 0.6926249861717224 validation multi-class accuracy = 0.8638\n",
      "epoch = 5 loss = 0.5817651152610779 validation multi-class accuracy = 0.8825\n",
      "epoch = 6 loss = 0.47855624556541443 validation multi-class accuracy = 0.8771\n",
      "epoch = 7 loss = 0.48744916915893555 validation multi-class accuracy = 0.8843\n",
      "epoch = 8 loss = 0.5083115696907043 validation multi-class accuracy = 0.8879\n",
      "epoch = 9 loss = 0.5208050608634949 validation multi-class accuracy = 0.8867\n",
      "epoch = 10 loss = 0.4798893630504608 validation multi-class accuracy = 0.8827\n",
      "epoch = 11 loss = 0.5027012825012207 validation multi-class accuracy = 0.8874\n",
      "epoch = 12 loss = 0.541517436504364 validation multi-class accuracy = 0.8874\n",
      "epoch = 13 loss = 0.4813820421695709 validation multi-class accuracy = 0.8850\n",
      "epoch = 14 loss = 0.46835851669311523 validation multi-class accuracy = 0.8832\n",
      "epoch = 15 loss = 0.5180773735046387 validation multi-class accuracy = 0.8790\n",
      "epoch = 16 loss = 0.451353520154953 validation multi-class accuracy = 0.8783\n",
      "epoch = 17 loss = 0.523042619228363 validation multi-class accuracy = 0.8850\n",
      "epoch = 18 loss = 0.5326690077781677 validation multi-class accuracy = 0.8822\n",
      "epoch = 19 loss = 0.5410427451133728 validation multi-class accuracy = 0.8806\n",
      "epoch = 20 loss = 0.5499688982963562 validation multi-class accuracy = 0.8867\n",
      "epoch = 20 loss = 0.5003023743629456 validation multi-class accuracy = 0.8909\n",
      "Training with 1 started\n",
      "17117 4280\n",
      "epoch = 1 loss = 0.5022203326225281 validation multi-class accuracy = 0.8748\n",
      "epoch = 2 loss = 0.5085079669952393 validation multi-class accuracy = 0.8743\n",
      "epoch = 3 loss = 0.499252587556839 validation multi-class accuracy = 0.8759\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "     # for training only, need nightly build pytorch\n",
    "\n",
    "    seed_everything(CFG['seed'])\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "        # we'll train fold 0 first\n",
    "        # if fold > 0:\n",
    "        #     break \n",
    "\n",
    "        print('Training with {} started'.format(fold))\n",
    "\n",
    "        print(len(trn_idx), len(val_idx))\n",
    "        train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx, data_root='/workspace/input/cassava-leaf-disease-classification/train_images/')\n",
    "\n",
    "        device = torch.device(CFG['device'])\n",
    "        \n",
    "        model = CassvaImgClassifier_NF(CFG['model_arch'], train.label.nunique(),CFG['img_size'], pretrained=True).to(device)\n",
    "        \n",
    "        scaler = GradScaler()   \n",
    "        #base_opt = torch.optim.AdamW(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "        base_opt = AdamP(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n",
    "        base_opt = AGC(model.parameters(), base_opt, clipping=CFG['clipping'])\n",
    "        optimizer = SWA(base_opt, swa_start=5*len(trn_idx)//CFG['train_bs'], swa_freq=len(trn_idx)//CFG['train_bs'])\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CFG['T_0'], T_mult=1, eta_min=CFG['min_lr'], last_epoch=-1)\n",
    "        \n",
    "        #loss_tr = LabelSmoothingLoss(classes=CFG['target_size'], smoothing=CFG['smoothing']).to(device)\n",
    "        loss_tr = LabelSmoothingCrossEntropy(smoothing=CFG['smoothing'])\n",
    "        # loss_tr = nn.CrossEntropyLoss().to(device) #MyCrossEntropyLoss().to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "        \n",
    "        for epoch in range(CFG['epochs']):\n",
    "            train_one_epoch(epoch, model, loss_tr, optimizer, train_loader, device, scheduler=scheduler, schd_batch_update=False)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False)\n",
    "\n",
    "            #torch.save(model.state_dict(),'./{}/{}_fold_{}_{}'.format(CFG['model_path'], CFG['model_arch'], fold, epoch)) \n",
    "        optimizer.swap_swa_sgd()\n",
    "        optimizer.bn_update(train_loader, model, device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False)\n",
    "            torch.save(model.state_dict(),'/workspace/{}/swa_{}_fold_{}_{}'.format(CFG['model_path'], CFG['model_arch'], fold, epoch)) \n",
    "        #torch.save(model.cnn_model.state_dict(),'{}/cnn_model_fold_{}_{}'.format(CFG['model_path'], fold, CFG['tag']))\n",
    "        del model, optimizer, train_loader, val_loader, scaler, scheduler\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "duration": 8637.721674,
   "end_time": "2020-11-23T15:56:40.428882",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-23T13:32:42.707208",
   "version": "2.1.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
